{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8104cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from s4hci.models.noise import S4Noise\n",
    "from s4hci.models.planet import S4Planet\n",
    "from s4hci.models.normalization import S4FrameNormalization\n",
    "from s4hci.utils.adi_tools import combine_residual_stack\n",
    "from s4hci.utils.data_handling import save_as_fits, load_adi_data\n",
    "from s4hci.models.rotation import FieldRotationModel\n",
    "\n",
    "from applefy.utils.file_handling import open_fits\n",
    "from applefy.utils.fake_planets import add_fake_planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fff3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe94b6",
   "metadata": {},
   "source": [
    "# Load the data and insert the fake planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0832fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.) Load the dataset\n",
    "science_data, raw_angles, raw_psf_template_data = \\\n",
    "    load_adi_data(\n",
    "        hdf5_dataset=\"/fast/mbonse/s4/30_data/HD22049_303_199_C-0065_C_.hdf5\",\n",
    "        data_tag=\"object\",\n",
    "        psf_template_tag=\"psf_template\",\n",
    "        para_tag=\"header_object/PARANG\")\n",
    "\n",
    "science_data = science_data[::2, 12:-12, 12:-12]\n",
    "raw_angles = raw_angles[::2]\n",
    "\n",
    "# Background subtraction of the PSF template\n",
    "psf_template_data = np.median(raw_psf_template_data, axis=0)\n",
    "psf_template_data = psf_template_data - np.min(psf_template_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d50afd",
   "metadata": {},
   "source": [
    "# Implement the current training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5deb5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationS4:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        science_data,\n",
    "        psf_template,\n",
    "        lambda_reg,\n",
    "        parang,\n",
    "        inverse=1,\n",
    "        conv=False,\n",
    "        work_dir=None,\n",
    "        psf_cut_radius=4.0,\n",
    "        mask_radius=5.5):\n",
    "\n",
    "        # 1.) Save the data\n",
    "        self.device = 0\n",
    "        self.science_data = torch.from_numpy(science_data).float()\n",
    "        self.psf_template = psf_template\n",
    "        self.data_image_size = self.science_data.shape[-1]\n",
    "        self.parang = parang\n",
    "        \n",
    "        if work_dir is not None:\n",
    "            self.work_dir = Path(work_dir)\n",
    "        else:\n",
    "            self.work_dir = None\n",
    "        self.residuals_dir, self.tensorboard_dir, self.models_dir = \\\n",
    "            self._setup_working_dir()\n",
    "\n",
    "        # 2.) Create the noise model\n",
    "        self.noise_model = S4Noise(\n",
    "            data_image_size=self.data_image_size,\n",
    "            psf_template=psf_template,\n",
    "            lambda_reg=lambda_reg,\n",
    "            cut_radius_psf=psf_cut_radius,\n",
    "            mask_template_setup=(\"radius\", mask_radius),\n",
    "            convolve=conv,\n",
    "            verbose=True).float()\n",
    "        \n",
    "        # 2.) Create the filed rotation model\n",
    "        self.rotation_model = FieldRotationModel(\n",
    "            all_angles=parang * inverse, # TODO check if this is the right direction\n",
    "            input_size=self.data_image_size,\n",
    "            subsample=1,\n",
    "            inverse=False,\n",
    "            register_grid=True)\n",
    "\n",
    "        # 3.) Create normalization model\n",
    "        self.normalization_model = S4FrameNormalization(\n",
    "            image_size=self.data_image_size,\n",
    "            normalization_type=\"normal\")\n",
    "\n",
    "        self.normalization_model.prepare_normalization(\n",
    "            science_data=self.science_data)\n",
    "        \n",
    "        # 4.) For tensorboard\n",
    "        self.tensorboard_logger = None\n",
    "        self.fine_tune_start_time = None\n",
    "        \n",
    "    def _setup_working_dir(self):\n",
    "        if self.work_dir is None:\n",
    "            return None, None, None\n",
    "\n",
    "        # make sure the working dir is a dir\n",
    "        self.work_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        residuals_dir = self.work_dir / \"residuals\"\n",
    "        tensorboard_dir = self.work_dir / \"tensorboard\"\n",
    "        models_dir = self.work_dir / \"models\"\n",
    "\n",
    "        residuals_dir.mkdir(exist_ok=True)\n",
    "        tensorboard_dir.mkdir(exist_ok=True)\n",
    "        models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        return residuals_dir, tensorboard_dir, models_dir\n",
    "        \n",
    "    def _create_tensorboard_logger(self):\n",
    "        time_str = datetime.now().strftime(\"%Y-%m-%d-%Hh%Mm%Ss\")\n",
    "        self.fine_tune_start_time = time_str\n",
    "        current_logdir = self.tensorboard_dir / \\\n",
    "            Path(self.fine_tune_start_time)\n",
    "        current_logdir.mkdir()\n",
    "        self.tensorboard_logger = SummaryWriter(current_logdir)\n",
    "        \n",
    "    def _logg_loss_values(\n",
    "            self,\n",
    "            epoch,\n",
    "            loss_recon,\n",
    "            loss_reg):\n",
    "\n",
    "        if self.work_dir is None:\n",
    "            return\n",
    "\n",
    "        self.tensorboard_logger.add_scalar(\n",
    "            \"Loss/Reconstruction_loss\",\n",
    "            loss_recon,\n",
    "            epoch)\n",
    "\n",
    "        self.tensorboard_logger.add_scalar(\n",
    "            \"Loss/Regularization_loss\",\n",
    "            loss_reg,\n",
    "            epoch)\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_for_tensorboard(frame_in):\n",
    "        image_for_tb = deepcopy(frame_in)\n",
    "        image_for_tb -= np.min(image_for_tb)\n",
    "        image_for_tb /= np.max(image_for_tb)\n",
    "        return image_for_tb\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def compute_residual(\n",
    "            self,\n",
    "            num_cpus=8,\n",
    "            subtract_temporal_average=False\n",
    "    ):\n",
    "        # 1.) normalize and reshape the data\n",
    "        x_norm = self.normalization_model(self.science_data)\n",
    "        science_norm_flatten = x_norm.view(x_norm.shape[0], -1)\n",
    "\n",
    "        # 2.) compute the noise estimate\n",
    "        noise_estimate = self.noise_model(science_norm_flatten)\n",
    "\n",
    "        # 3.) compute and reshape the residual sequence\n",
    "        residual_sequence = science_norm_flatten - noise_estimate\n",
    "        residual_stack = residual_sequence.view(\n",
    "            self.science_data.shape[0],\n",
    "            self.noise_model.image_size,\n",
    "            self.noise_model.image_size).detach().cpu().numpy()\n",
    "\n",
    "        # 4.) derotate and stack the residual sequence\n",
    "        residual_image = combine_residual_stack(\n",
    "            residual_stack=residual_stack,\n",
    "            angles=self.parang,\n",
    "            combine=\"mean\",\n",
    "            subtract_temporal_average=subtract_temporal_average,\n",
    "            num_cpus=num_cpus)\n",
    "\n",
    "        return residual_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c055c",
   "metadata": {},
   "source": [
    "# Implement LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9fc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"0149b\"\n",
    "\n",
    "# add the fake planet\n",
    "fake_planet_config_file = \"/fast/mbonse/s4/70_results/07_partial_contrast_grid/HD22049_303_199_C-0065_C_/configs_cgrid/exp_ID_\" + dataset_id + \".json\"\n",
    "with open(fake_planet_config_file) as json_file:\n",
    "    fake_planet_config = json.load(json_file)\n",
    "\n",
    "data_with_fake_planet = add_fake_planets(\n",
    "    input_stack=science_data,\n",
    "    psf_template=psf_template_data,\n",
    "    parang=raw_angles,\n",
    "    dit_psf_template=0.004256,\n",
    "    dit_science=0.08,\n",
    "    experiment_config=fake_planet_config,\n",
    "    scaling_factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e6d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4dcb9b68da4994ac17608eec3de8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 0\n",
    "batch_size=-1\n",
    "num_epochs=500\n",
    "lambda_reg=0\n",
    "\n",
    "# Create the model\n",
    "s4_model = RotationS4(\n",
    "    science_data=data_with_fake_planet,\n",
    "    psf_template=psf_template_data,\n",
    "    lambda_reg=lambda_reg,\n",
    "    inverse=1,\n",
    "    conv=True,\n",
    "    mask_radius=5.5,\n",
    "    work_dir=\"/fast/mbonse/s4/70_results/09_new_rotation_loss/fft_loss/\",\n",
    "    parang=raw_angles)\n",
    "\n",
    "# Create the tensorboard logger\n",
    "if s4_model.work_dir is not None:\n",
    "    s4_model._create_tensorboard_logger()\n",
    "\n",
    "# 1.) normalize the science data\n",
    "x_norm = s4_model.normalization_model(s4_model.science_data)\n",
    "science_norm_flatten = x_norm.view(x_norm.shape[0], -1)\n",
    "\n",
    "# 2.) move models to the GPU\n",
    "s4_model.noise_model = s4_model.noise_model.to(device)\n",
    "s4_model.rotation_model = s4_model.rotation_model.to(device)\n",
    "\n",
    "# 3.) Create the optimizer and add the parameters we want to optimize\n",
    "optimizer = optim.LBFGS(\n",
    "    [s4_model.noise_model.betas_raw, ],\n",
    "    max_iter=20,\n",
    "    history_size=5)\n",
    "\n",
    "# 4.) Create the DataLoader\n",
    "if batch_size == -1:\n",
    "    batch_size = x_norm.shape[0]\n",
    "    # upload the data to the device\n",
    "    science_norm_flatten = science_norm_flatten.to(device)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    science_norm_flatten,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "# 5.) Run the fine-tuning\n",
    "# needed for gradient accumulation in order to normalize the loss\n",
    "num_steps_per_epoch = len(data_loader)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for tmp_frames in data_loader:\n",
    "        # 0.) upload tmp_frames if needed\n",
    "        if tmp_frames.device != torch.device(device):\n",
    "            tmp_frames = tmp_frames.to(device)\n",
    "\n",
    "        def full_closure():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 1.) run the forward path of the noise model\n",
    "            s4_model.noise_model.compute_betas()\n",
    "            noise_estimate = s4_model.noise_model(tmp_frames)\n",
    "\n",
    "            # 2.) compute the residual and rotate it\n",
    "            residual_sequence = tmp_frames - noise_estimate\n",
    "            residual_sequence = residual_sequence.view(\n",
    "                residual_sequence.shape[0],\n",
    "                1,\n",
    "                s4_model.data_image_size,\n",
    "                s4_model.data_image_size)\n",
    "\n",
    "            rotated_frames = s4_model.rotation_model(\n",
    "                residual_sequence,\n",
    "                parang_idx=torch.arange(len(residual_sequence)))\n",
    "\n",
    "            # 2.) Compute the loss\n",
    "            frames_no_planet = rotated_frames - torch.mean(rotated_frames, axis=0)\n",
    "            \n",
    "            temporal_spectrum = torch.fft.rfft(frames_no_planet, axis=0).abs()**2\n",
    "            scaling = torch.flip(torch.arange(temporal_spectrum.shape[0]), dims=[0])\n",
    "            temporal_spectrum *= scaling.to(device).view(-1, 1, 1, 1)\n",
    "            temporal_spectrum[:5] *= 50\n",
    "            \n",
    "            loss_recon = temporal_spectrum.sum()\n",
    "\n",
    "            loss_reg = (s4_model.noise_model.betas_raw ** 2).sum() \\\n",
    "                * s4_model.noise_model.lambda_reg \\\n",
    "                / num_steps_per_epoch / rotated_frames.shape[0]\n",
    "\n",
    "            # 3.) Backward\n",
    "            loss = loss_recon + loss_reg\n",
    "            loss.backward()\n",
    "\n",
    "            # get the residual\n",
    "            residual = torch.mean(rotated_frames, axis=0)[0].detach().cpu().numpy()\n",
    "\n",
    "            return loss, residual\n",
    "\n",
    "        def loss_closure():\n",
    "            return full_closure()[0]\n",
    "\n",
    "\n",
    "        optimizer.step(loss_closure)\n",
    "        # 4.) Track the current loss\n",
    "        current_loss, current_residual = full_closure()\n",
    "\n",
    "    # 5.) Logg the information\n",
    "    s4_model._logg_loss_values(\n",
    "        epoch=epoch,\n",
    "        loss_recon=current_loss,\n",
    "        loss_reg=0)\n",
    "\n",
    "    s4_model.tensorboard_logger.add_image(\n",
    "        \"Images/Residual\",\n",
    "        s4_model._normalize_for_tensorboard(current_residual),\n",
    "        epoch,\n",
    "        dataformats=\"HW\")\n",
    "\n",
    "    if epoch % 20==19:\n",
    "        tmp_residual_dir = s4_model.residuals_dir / \\\n",
    "            Path(s4_model.fine_tune_start_time)\n",
    "        tmp_residual_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        save_as_fits(\n",
    "            current_residual,\n",
    "            tmp_residual_dir /\n",
    "            Path(\"Residual_epoch_\" + str(epoch).zfill(4)\n",
    "                 + \".fits\"),\n",
    "            overwrite=True)\n",
    "\n",
    "# 7.) Clean up GPU\n",
    "s4_model.noise_model = s4_model.noise_model.cpu()\n",
    "s4_model.rotation_model = s4_model.rotation_model.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d78533",
   "metadata": {},
   "source": [
    "# Test pytorch FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_signal1 = torch.sin(torch.arange(1000)/20)\n",
    "test_signal2 = torch.sin(torch.arange(1000)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b026f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_signal1)\n",
    "plt.plot(test_signal2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f17781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.fft.fft(test_signal1).abs())\n",
    "plt.plot(torch.fft.fft(test_signal2).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e26c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flip(torch.arange(10),dims=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b31a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
