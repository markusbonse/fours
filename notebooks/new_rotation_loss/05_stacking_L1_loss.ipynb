{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8104cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from s4hci.models.noise import S4Noise\n",
    "from s4hci.models.planet import S4Planet\n",
    "from s4hci.models.normalization import S4FrameNormalization\n",
    "from s4hci.utils.adi_tools import combine_residual_stack\n",
    "from s4hci.utils.data_handling import save_as_fits, load_adi_data\n",
    "from s4hci.models.rotation import FieldRotationModel\n",
    "\n",
    "from applefy.utils.file_handling import open_fits\n",
    "from applefy.utils.fake_planets import add_fake_planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fff3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe94b6",
   "metadata": {},
   "source": [
    "# Load the data and insert the fake planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0832fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.) Load the dataset\n",
    "science_data, raw_angles, raw_psf_template_data = \\\n",
    "    load_adi_data(\n",
    "        hdf5_dataset=\"/fast/mbonse/s4/30_data/HD22049_303_199_C-0065_C_.hdf5\",\n",
    "        data_tag=\"object\",\n",
    "        psf_template_tag=\"psf_template\",\n",
    "        para_tag=\"header_object/PARANG\")\n",
    "\n",
    "science_data = science_data[:, 12:-12, 12:-12]\n",
    "raw_angles = raw_angles[:]\n",
    "\n",
    "# Background subtraction of the PSF template\n",
    "psf_template_data = np.median(raw_psf_template_data, axis=0)\n",
    "psf_template_data = psf_template_data - np.min(psf_template_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6fceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"0105c\"\n",
    "\n",
    "# add the fake planet\n",
    "fake_planet_config_file = \"/fast/mbonse/s4/70_results/07_partial_contrast_grid/HD22049_303_199_C-0065_C_/configs_cgrid/exp_ID_\" + dataset_id + \".json\"\n",
    "with open(fake_planet_config_file) as json_file:\n",
    "    fake_planet_config = json.load(json_file)\n",
    "\n",
    "data_with_fake_planet = add_fake_planets(\n",
    "    input_stack=science_data,\n",
    "    psf_template=psf_template_data,\n",
    "    parang=raw_angles,\n",
    "    dit_psf_template=0.004256,\n",
    "    dit_science=0.08,\n",
    "    experiment_config=fake_planet_config,\n",
    "    scaling_factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16894590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "ss = 10\n",
    "angles_stacked = np.array([np.mean(i) for i in np.array_split(raw_angles, int(len(raw_angles) / ss))])\n",
    "science_stacked = np.array([np.mean(i, axis=0) for i in np.array_split(data_with_fake_planet, int(len(raw_angles) / ss))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d50afd",
   "metadata": {},
   "source": [
    "# Implement the current training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5deb5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationS4:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        science_data,\n",
    "        psf_template,\n",
    "        lambda_reg,\n",
    "        parang,\n",
    "        inverse=1,\n",
    "        conv=False,\n",
    "        work_dir=None,\n",
    "        psf_cut_radius=4.0,\n",
    "        mask_radius=5.5):\n",
    "\n",
    "        # 1.) Save the data\n",
    "        self.device = 0\n",
    "        self.science_data = torch.from_numpy(science_data).float()\n",
    "        self.psf_template = psf_template\n",
    "        self.data_image_size = self.science_data.shape[-1]\n",
    "        self.parang = parang\n",
    "        \n",
    "        if work_dir is not None:\n",
    "            self.work_dir = Path(work_dir)\n",
    "        else:\n",
    "            self.work_dir = None\n",
    "        self.residuals_dir, self.tensorboard_dir, self.models_dir = \\\n",
    "            self._setup_working_dir()\n",
    "\n",
    "        # 2.) Create the noise model\n",
    "        self.noise_model = S4Noise(\n",
    "            data_image_size=self.data_image_size,\n",
    "            psf_template=psf_template,\n",
    "            lambda_reg=lambda_reg,\n",
    "            cut_radius_psf=psf_cut_radius,\n",
    "            mask_template_setup=(\"radius\", mask_radius),\n",
    "            convolve=conv,\n",
    "            verbose=True).float()\n",
    "        \n",
    "        # 2.) Create the filed rotation model\n",
    "        self.rotation_model = FieldRotationModel(\n",
    "            all_angles=parang * inverse, # TODO check if this is the right direction\n",
    "            input_size=self.data_image_size,\n",
    "            subsample=1,\n",
    "            inverse=False,\n",
    "            register_grid=True)\n",
    "\n",
    "        # 3.) Create normalization model\n",
    "        self.normalization_model = S4FrameNormalization(\n",
    "            image_size=self.data_image_size,\n",
    "            normalization_type=\"normal\")\n",
    "\n",
    "        self.normalization_model.prepare_normalization(\n",
    "            science_data=self.science_data)\n",
    "        \n",
    "        # 4.) For tensorboard\n",
    "        self.tensorboard_logger = None\n",
    "        self.fine_tune_start_time = None\n",
    "        \n",
    "    def _setup_working_dir(self):\n",
    "        if self.work_dir is None:\n",
    "            return None, None, None\n",
    "\n",
    "        # make sure the working dir is a dir\n",
    "        self.work_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        residuals_dir = self.work_dir / \"residuals\"\n",
    "        tensorboard_dir = self.work_dir / \"tensorboard\"\n",
    "        models_dir = self.work_dir / \"models\"\n",
    "\n",
    "        residuals_dir.mkdir(exist_ok=True)\n",
    "        tensorboard_dir.mkdir(exist_ok=True)\n",
    "        models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        return residuals_dir, tensorboard_dir, models_dir\n",
    "        \n",
    "    def _create_tensorboard_logger(self):\n",
    "        time_str = datetime.now().strftime(\"%Y-%m-%d-%Hh%Mm%Ss\")\n",
    "        self.fine_tune_start_time = time_str\n",
    "        current_logdir = self.tensorboard_dir / \\\n",
    "            Path(self.fine_tune_start_time)\n",
    "        current_logdir.mkdir()\n",
    "        self.tensorboard_logger = SummaryWriter(current_logdir)\n",
    "        \n",
    "    def _logg_loss_values(\n",
    "            self,\n",
    "            epoch,\n",
    "            loss_recon,\n",
    "            loss_reg):\n",
    "\n",
    "        if self.work_dir is None:\n",
    "            return\n",
    "\n",
    "        self.tensorboard_logger.add_scalar(\n",
    "            \"Loss/Reconstruction_loss\",\n",
    "            loss_recon,\n",
    "            epoch)\n",
    "\n",
    "        self.tensorboard_logger.add_scalar(\n",
    "            \"Loss/Regularization_loss\",\n",
    "            loss_reg,\n",
    "            epoch)\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _normalize_for_tensorboard(frame_in):\n",
    "        image_for_tb = deepcopy(frame_in)\n",
    "        image_for_tb -= np.min(image_for_tb)\n",
    "        image_for_tb /= np.max(image_for_tb)\n",
    "        return image_for_tb\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def compute_residual(\n",
    "            self,\n",
    "            num_cpus=8,\n",
    "            subtract_temporal_average=False\n",
    "    ):\n",
    "        # 1.) normalize and reshape the data\n",
    "        x_norm = self.normalization_model(self.science_data)\n",
    "        science_norm_flatten = x_norm.view(x_norm.shape[0], -1)\n",
    "\n",
    "        # 2.) compute the noise estimate\n",
    "        noise_estimate = self.noise_model(science_norm_flatten)\n",
    "\n",
    "        # 3.) compute and reshape the residual sequence\n",
    "        residual_sequence = science_norm_flatten - noise_estimate\n",
    "        residual_stack = residual_sequence.view(\n",
    "            self.science_data.shape[0],\n",
    "            self.noise_model.image_size,\n",
    "            self.noise_model.image_size).detach().cpu().numpy()\n",
    "\n",
    "        # 4.) derotate and stack the residual sequence\n",
    "        residual_image = combine_residual_stack(\n",
    "            residual_stack=residual_stack,\n",
    "            angles=self.parang,\n",
    "            combine=\"mean\",\n",
    "            subtract_temporal_average=subtract_temporal_average,\n",
    "            num_cpus=num_cpus)\n",
    "\n",
    "        return residual_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c055c",
   "metadata": {},
   "source": [
    "# Train with L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e6d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1352b3f899b47d5a81fb56e449e267f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 0\n",
    "batch_size=-1\n",
    "num_epochs=200\n",
    "lambda_reg=500\n",
    "\n",
    "# Create the model\n",
    "s4_model = RotationS4(\n",
    "    science_data=science_stacked,\n",
    "    psf_template=psf_template_data,\n",
    "    lambda_reg=lambda_reg,\n",
    "    inverse=1,\n",
    "    conv=True,\n",
    "    mask_radius=5.5,\n",
    "    work_dir=\"/fast/mbonse/s4/70_results/09_new_rotation_loss/l1_vs_l2/\",\n",
    "    parang=angles_stacked)\n",
    "\n",
    "# Create the tensorboard logger\n",
    "if s4_model.work_dir is not None:\n",
    "    s4_model._create_tensorboard_logger()\n",
    "\n",
    "# 1.) normalize the science data\n",
    "x_norm = s4_model.normalization_model(s4_model.science_data)\n",
    "science_norm_flatten = x_norm.view(x_norm.shape[0], -1)\n",
    "science_norm_flatten = science_norm_flatten.to(device)\n",
    "\n",
    "# 2.) move models to the GPU\n",
    "s4_model.noise_model = s4_model.noise_model.to(device)\n",
    "s4_model.rotation_model = s4_model.rotation_model.to(device)\n",
    "\n",
    "# 3.) Create the optimizer and add the parameters we want to optimize\n",
    "optimizer = optim.LBFGS(\n",
    "    [s4_model.noise_model.betas_raw, ],\n",
    "    max_iter=20,\n",
    "    history_size=10)\n",
    "\n",
    "# 4.) Run the training\n",
    "# needed for gradient accumulation in order to normalize the loss\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    def full_closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1.) run the forward path of the noise model\n",
    "        s4_model.noise_model.compute_betas()\n",
    "        noise_estimate = s4_model.noise_model(science_norm_flatten)\n",
    "\n",
    "        # 2.) compute the residual and rotate it\n",
    "        residual_sequence = science_norm_flatten - noise_estimate\n",
    "        residual_sequence = residual_sequence.view(\n",
    "            residual_sequence.shape[0],\n",
    "            1,\n",
    "            s4_model.data_image_size,\n",
    "            s4_model.data_image_size)\n",
    "\n",
    "        rotated_frames = s4_model.rotation_model(\n",
    "            residual_sequence,\n",
    "            parang_idx=torch.arange(len(residual_sequence)))\n",
    "\n",
    "        # 2.) Compute the loss L1 loss\n",
    "        residual_mean = torch.mean(rotated_frames, axis=0)\n",
    "        loss_recon = torch.abs(rotated_frames - residual_mean).sum()\n",
    "        #loss_recon = ((rotated_frames - residual_mean)**2).sum()\n",
    "\n",
    "        loss_reg = (s4_model.noise_model.betas_raw ** 2).sum() \\\n",
    "            * s4_model.noise_model.lambda_reg / rotated_frames.shape[0]\n",
    "\n",
    "        # 3.) Backward\n",
    "        loss = loss_recon + loss_reg\n",
    "        loss.backward()\n",
    "\n",
    "        # get the residual\n",
    "        residual = residual_mean[0].detach().cpu().numpy()\n",
    "        residual_median = torch.median(rotated_frames, axis=0)[0][0].detach().cpu().numpy()\n",
    "\n",
    "        return loss, residual, residual_median\n",
    "\n",
    "    def loss_closure():\n",
    "        return full_closure()[0]\n",
    "\n",
    "\n",
    "    optimizer.step(loss_closure)\n",
    "    # 4.) Track the current loss\n",
    "    current_loss, current_residual, current_residual_median = full_closure()\n",
    "\n",
    "    # 5.) Logg the information\n",
    "    s4_model._logg_loss_values(\n",
    "        epoch=epoch,\n",
    "        loss_recon=current_loss,\n",
    "        loss_reg=0)\n",
    "\n",
    "    s4_model.tensorboard_logger.add_image(\n",
    "        \"Images/Residual\",\n",
    "        s4_model._normalize_for_tensorboard(current_residual),\n",
    "        epoch,\n",
    "        dataformats=\"HW\")\n",
    "    \n",
    "    s4_model.tensorboard_logger.add_image(\n",
    "        \"Images/Residual_Median\",\n",
    "        s4_model._normalize_for_tensorboard(current_residual_median),\n",
    "        epoch,\n",
    "        dataformats=\"HW\")\n",
    "\n",
    "    if epoch % 20==19:\n",
    "        tmp_residual_dir = s4_model.residuals_dir / \\\n",
    "            Path(s4_model.fine_tune_start_time)\n",
    "        tmp_residual_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        save_as_fits(\n",
    "            current_residual,\n",
    "            tmp_residual_dir /\n",
    "            Path(\"Residual_epoch_\" + str(epoch).zfill(4)\n",
    "                 + \".fits\"),\n",
    "            overwrite=True)\n",
    "        \n",
    "        save_as_fits(\n",
    "            current_residual_median,\n",
    "            tmp_residual_dir /\n",
    "            Path(\"Residual_Median_epoch_\" + str(epoch).zfill(4)\n",
    "                 + \".fits\"),\n",
    "            overwrite=True)\n",
    "\n",
    "# 7.) Clean up GPU\n",
    "s4_model.noise_model = s4_model.noise_model.cpu()\n",
    "s4_model.rotation_model = s4_model.rotation_model.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717fc469",
   "metadata": {},
   "source": [
    "# Residuals with L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "batch_size=-1\n",
    "num_epochs=200\n",
    "lambda_reg=500\n",
    "\n",
    "# Create the model\n",
    "s4_model = RotationS4(\n",
    "    science_data=science_stacked,\n",
    "    psf_template=psf_template_data,\n",
    "    lambda_reg=lambda_reg,\n",
    "    inverse=1,\n",
    "    conv=True,\n",
    "    mask_radius=5.5,\n",
    "    work_dir=\"/fast/mbonse/s4/70_results/09_new_rotation_loss/l1_vs_l2/\",\n",
    "    parang=angles_stacked)\n",
    "\n",
    "# Create the tensorboard logger\n",
    "if s4_model.work_dir is not None:\n",
    "    s4_model._create_tensorboard_logger()\n",
    "\n",
    "# 1.) normalize the science data\n",
    "x_norm = s4_model.normalization_model(s4_model.science_data)\n",
    "science_norm_flatten = x_norm.view(x_norm.shape[0], -1)\n",
    "science_norm_flatten = science_norm_flatten.to(device)\n",
    "\n",
    "# 2.) move models to the GPU\n",
    "s4_model.noise_model = s4_model.noise_model.to(device)\n",
    "s4_model.rotation_model = s4_model.rotation_model.to(device)\n",
    "\n",
    "# 3.) Create the optimizer and add the parameters we want to optimize\n",
    "optimizer = optim.LBFGS(\n",
    "    [s4_model.noise_model.betas_raw, ],\n",
    "    max_iter=20,\n",
    "    history_size=10)\n",
    "\n",
    "# 4.) Run the training\n",
    "# needed for gradient accumulation in order to normalize the loss\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    def full_closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1.) run the forward path of the noise model\n",
    "        s4_model.noise_model.compute_betas()\n",
    "        noise_estimate = s4_model.noise_model(science_norm_flatten)\n",
    "\n",
    "        # 2.) compute the residual and rotate it\n",
    "        residual_sequence = science_norm_flatten - noise_estimate\n",
    "        residual_sequence = residual_sequence.view(\n",
    "            residual_sequence.shape[0],\n",
    "            1,\n",
    "            s4_model.data_image_size,\n",
    "            s4_model.data_image_size)\n",
    "\n",
    "        rotated_frames = s4_model.rotation_model(\n",
    "            residual_sequence,\n",
    "            parang_idx=torch.arange(len(residual_sequence)))\n",
    "\n",
    "        # 2.) Compute the loss L2 loss\n",
    "        residual_mean = torch.mean(rotated_frames, axis=0)\n",
    "        #loss_recon = torch.abs(rotated_frames - residual_mean).sum()\n",
    "        loss_recon = ((rotated_frames - residual_mean)**2).sum()\n",
    "\n",
    "        loss_reg = (s4_model.noise_model.betas_raw ** 2).sum() \\\n",
    "            * s4_model.noise_model.lambda_reg / rotated_frames.shape[0]\n",
    "\n",
    "        # 3.) Backward\n",
    "        loss = loss_recon + loss_reg\n",
    "        loss.backward()\n",
    "\n",
    "        # get the residual\n",
    "        residual = residual_mean[0].detach().cpu().numpy()\n",
    "        residual_median = torch.median(rotated_frames, axis=0)[0][0].detach().cpu().numpy()\n",
    "\n",
    "        return loss, residual, residual_median\n",
    "\n",
    "    def loss_closure():\n",
    "        return full_closure()[0]\n",
    "\n",
    "\n",
    "    optimizer.step(loss_closure)\n",
    "    # 4.) Track the current loss\n",
    "    current_loss, current_residual, current_residual_median = full_closure()\n",
    "\n",
    "    # 5.) Logg the information\n",
    "    s4_model._logg_loss_values(\n",
    "        epoch=epoch,\n",
    "        loss_recon=current_loss,\n",
    "        loss_reg=0)\n",
    "\n",
    "    s4_model.tensorboard_logger.add_image(\n",
    "        \"Images/Residual\",\n",
    "        s4_model._normalize_for_tensorboard(current_residual),\n",
    "        epoch,\n",
    "        dataformats=\"HW\")\n",
    "    \n",
    "    s4_model.tensorboard_logger.add_image(\n",
    "        \"Images/Residual_Median\",\n",
    "        s4_model._normalize_for_tensorboard(current_residual_median),\n",
    "        epoch,\n",
    "        dataformats=\"HW\")\n",
    "\n",
    "    if epoch % 20==19:\n",
    "        tmp_residual_dir = s4_model.residuals_dir / \\\n",
    "            Path(s4_model.fine_tune_start_time)\n",
    "        tmp_residual_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        save_as_fits(\n",
    "            current_residual,\n",
    "            tmp_residual_dir /\n",
    "            Path(\"Residual_epoch_\" + str(epoch).zfill(4)\n",
    "                 + \".fits\"),\n",
    "            overwrite=True)\n",
    "        \n",
    "        save_as_fits(\n",
    "            current_residual_median,\n",
    "            tmp_residual_dir /\n",
    "            Path(\"Residual_Median_epoch_\" + str(epoch).zfill(4)\n",
    "                 + \".fits\"),\n",
    "            overwrite=True)\n",
    "\n",
    "# 7.) Clean up GPU\n",
    "s4_model.noise_model = s4_model.noise_model.cpu()\n",
    "s4_model.rotation_model = s4_model.rotation_model.cpu()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd91091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
